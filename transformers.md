---
title: Transformers
layout: default
parent: DL Basics
nav_order: 1
---

Transformers have shown strong results on vision and language compared with conventional CNNs and RNNs. Especially on large-scale dataset, the performance of transformers is often significantly better than others.

## Table of contents
- [Table of contents](#table-of-contents)
- [Transformers and self-attention mechanism](#transformers-and-self-attention-mechanism)
- [Large-language models (LLMs)](#large-language-models-llms)
- [Vision transformers (ViTs)](#vision-transformers-vits)
- [Transformers alternatives](#transformers-alternatives)
  - [Mamba](#mamba)
  - [Vision Mamba](#vision-mamba)
- [Conclusion](#conclusion)
- [Reference](#reference)

## Transformers and self-attention mechanism

## Large-language models (LLMs)

## Vision transformers (ViTs)

## Transformers alternatives

### Mamba

### Vision Mamba


## Conclusion

----

## Reference
1. [NeurIPS'17] [Attention Is All You Need](https://arxiv.org/abs/1706.03762), Google Research
2. [NeurIPS'20] [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165), OpenAI
3. [arXiv 2020] [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361), JUH and OpenAI
4. [ICLR'20] [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929), Google Research
5. [ICCV'21] [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](https://arxiv.org/abs/2103.14030), Microsoft Research Asia
6. [ECCV'22] [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872), Meta AI
7. [arXiv 2023.12] [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://github.com/state-spaces/mamba), Princeton University
8. [ICML'24] [Transformers are SSMs: Generalized Models and Efficient Algorithms Through Structured State Space Duality](https://github.com/state-spaces/mamba), Princeton University
9. [ICML'24] [Efficient Visual Representation Learning with Bidirectional State Space Model](https://github.com/hustvl/Vim), Huazhong University of Science and Technology
